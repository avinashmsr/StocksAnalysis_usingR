---
title: "Data Mining Final Project Team 10"
author: "Team 10"
date: "2022-11-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lubridate)
library(GGally)
library(visreg)
library(fastDummies)
library(caTools)
library(ROCR)
library(rpart)
library(rpart.plot)
library(randomForest)
library(patchwork)
library("neuralnet")
```

```{r}
df.ko.stock <- read.csv("KO R data.csv", stringsAsFactors= TRUE)
head(df.ko.stock)

```

### Variable Descriptions:

#### KOnextday=Continuous dependant variable	Price change of KO on the following day

#### KOupdown=Binary dependant variable	Positive (1) or negative (0) price change of KO on the following day

#### KOvolume=	Independent variable	KO price change

#### KOchange=	Independent variable	KO volume change

#### Dividendday=	Independent variable	1 = day dividend was paid, 0= all other days

#### Dividendminus1wk=	Independent variable	1= day that was within 1 week before dividend was paid, 0 = all other days

#### Dividendminus2wk=	Independent variable	1= day that was within 2 week before dividend was paid, 0 = all other days

#### Dividendminus3wk=	Independent variable	1= day that was within 3 week before dividend was paid, 0 = all other days

#### Dividendplus1wk=	Independent variable	1= day that was within 1 week after dividend was paid, 0 = all other days

#### NYSEchange=	Independent variable	NYSE price change

#### Pepsichange=	Independent variable	Pepsi price change

#### KO10dayMA=	Independent variable	KO 10 day moving average

#### PPIChange=	Independent variable	PPI monthly change

#### MCDchange=	Independent variable	MCD price change

```{r}
str(df.ko.stock)
```

```{r}
summary(df.ko.stock)
```

```{r}
df.ko.stock$Date2 <- ymd(df.ko.stock$Date)
df.ko.stock$month <- month(df.ko.stock$Date2)

df.ko.stock <- df.ko.stock %>% relocate(Date2,month)
#head(df.ko.stock)
```

```{r}
df.ko.stock <- dummy_cols(df.ko.stock, select_columns=c('month'), remove_selected_columns = TRUE)

df.ko.stock2 <- df.ko.stock %>% subset(select=-c(Date, Date2, month_1))

df.ko.stock2 <- na.omit(df.ko.stock2) # to solve/handle the null values
head(df.ko.stock2)

nrow(df.ko.stock)
nrow(df.ko.stock2)
```

### Linear Regression Model:
```{r}
linear.reg.model = lm(KOnextday ~.-KOupdown, data=df.ko.stock2)
summary(linear.reg.model)
```

### Logistic Regression Model:
```{r}
logistic.reg.model = glm(KOupdown ~.-KOnextday, data=df.ko.stock2, family="binomial")
summary(logistic.reg.model)
```

```{r}
coef(logistic.reg.model)
exp(coef(logistic.reg.model))
coeftable <- data.frame(col1=coef(logistic.reg.model),col2=exp(coef(logistic.reg.model)))
colnames(coeftable)<-c('Coefficient (log-odds)','e^coefficient (odds)')
coeftable
```

#### Confusion Matrix

Define a threshold and make predictions for default:

```{r}
#The threshold is the value above which Y will be classified as 1 and below or equal  Y will be classified as 0. 
threshold1 = 0.25
threshold2 = 0.5
threshold3 = 0.6
threshold4 = 0.7
threshold5 = 0.75
df.ko.stock2$predProbs = predict(logistic.reg.model, newdata=df.ko.stock2, type="response")
df.ko.stock2$pred.price.change.th1 = ifelse(df.ko.stock2$predProbs >= threshold1, 1, 0)
df.ko.stock2$pred.price.change.th2 = ifelse(df.ko.stock2$predProbs >= threshold2, 1, 0)
df.ko.stock2$pred.price.change.th3 = ifelse(df.ko.stock2$predProbs >= threshold3, 1, 0)
df.ko.stock2$pred.price.change.th4 = ifelse(df.ko.stock2$predProbs >= threshold4, 1, 0)
df.ko.stock2$pred.price.change.th5 = ifelse(df.ko.stock2$predProbs >= threshold5, 1, 0)
#head(df.ko.stock2)
```

```{r}
df.ko.stock2 <- df.ko.stock2 %>%relocate(KOupdown,pred.price.change.th1,pred.price.change.th2,pred.price.change.th3,pred.price.change.th4,pred.price.change.th5, predProbs)
#head(df.ko.stock2)
```

**Now we can compare actual defaults vs predicted.**


```{r}
ConfMatrix1 <- table(df.ko.stock2$KOupdown, df.ko.stock2$pred.price.change.th1)
ConfMatrix2 <- table(df.ko.stock2$KOupdown, df.ko.stock2$pred.price.change.th2)
ConfMatrix3 <- table(df.ko.stock2$KOupdown, df.ko.stock2$pred.price.change.th3)
ConfMatrix4 <- table(df.ko.stock2$KOupdown, df.ko.stock2$pred.price.change.th4)
ConfMatrix5 <- table(df.ko.stock2$KOupdown, df.ko.stock2$pred.price.change.th5)

colnames(ConfMatrix2)<-c("Pred False", "Pred True")
rownames(ConfMatrix2)<-c("Obs False", "Obs True")
colnames(ConfMatrix3)<-c("Pred False", "Pred True")
rownames(ConfMatrix3)<-c("Obs False", "Obs True")
colnames(ConfMatrix4)<-c("Pred False", "Pred True")
rownames(ConfMatrix4)<-c("Obs False", "Obs True")
colnames(ConfMatrix5)<-c("Pred False", "Pred True")
rownames(ConfMatrix5)<-c("Obs False", "Obs True")

print("For Threshold 1 - 0.25")
ConfMatrix1
writeLines("")
print("For Threshold 2 - 0.5")
ConfMatrix2
writeLines("")
print("For Threshold 3 - 0.6")
ConfMatrix3
writeLines("")
print("For Threshold 4 - 0.7")
ConfMatrix4
writeLines("")
print("For Threshold 5 - 0.75")
ConfMatrix5
```

#### Creating the resuable function calculate_metrics - can be used in multiple places
```{r}
calculate_metrics <- function(predicted,actual){
TN <- sum(df.ko.stock2[,predicted]==0 & df.ko.stock2[,actual]==0)
FN <- sum(df.ko.stock2[,predicted]==0 & df.ko.stock2[,actual]==1)
TP <- sum(df.ko.stock2[,predicted]==1 & df.ko.stock2[,actual]==1)
FP <- sum(df.ko.stock2[,predicted]==1 & df.ko.stock2[,actual]==0)

#Getting Accuracy, Sensitivity and Specificity:

ACCU <- (TN+TP)/(TN+TP+FN+FP)
SENS <- TP/(TP+FN)
SPEC <- TN/(TN+FP)

return (list(accuracy = round(ACCU,4),sensitivity=round(SENS,4),specificity=round(SPEC,4)))
}
```



```{r}

result.th1 <- calculate_metrics("pred.price.change.th1","KOupdown")
print(paste("Logistic regression model Threshold 1 - 0.25: Accuracy is:",result.th1$accuracy,"Sensitivity is:",result.th1$sensitivity,"Specificity is:",result.th1$specificity))

result.th2 <- calculate_metrics("pred.price.change.th2","KOupdown")
print(paste("Logistic regression model Threshold 2 - 0.5: Accuracy is:",result.th2$accuracy,"Sensitivity is:",result.th2$sensitivity,"Specificity is:",result.th2$specificity))

result.th3 <- calculate_metrics("pred.price.change.th3","KOupdown")
print(paste("Logistic regression model Threshold 3 - 0.6: Accuracy is:",result.th3$accuracy,"Sensitivity is:",result.th3$sensitivity,"Specificity is:",result.th3$specificity))

result.th4 <- calculate_metrics("pred.price.change.th4","KOupdown")
print(paste("Logistic regression model Threshold 4 - 0.7: Accuracy is:",result.th4$accuracy,"Sensitivity is:",result.th4$sensitivity,"Specificity is:",result.th4$specificity))

result.th5 <- calculate_metrics("pred.price.change.th5","KOupdown")
print(paste("Logistic regression model Threshold 5 - 0.75: Accuracy is:",result.th5$accuracy,"Sensitivity is:",result.th5$sensitivity,"Specificity is:",result.th5$specificity))
```


### Next, Building Regression Tree Model

#### taking fresh dataframe prior to building the regression tree
```{r}
df.ko.stock3 <- df.ko.stock2 %>% subset(select=-c(KOupdown,pred.price.change.th1,pred.price.change.th2,pred.price.change.th3 ,pred.price.change.th4,pred.price.change.th5,predProbs))
head(df.ko.stock3)
```

#### Splitting Dataset into training and test

We will leave 80% of observations in the training set and 20% in the test set.

```{r}
#set.seed just keeps results random but constant for all using the same seed (so we all will have the same results)
set.seed(1127, sample.kind = "Rejection")
spl = sample(nrow(df.ko.stock3),0.8*nrow(df.ko.stock3))
head(spl)
```

```{r}
# Now lets split our dataset into train and test:
train.df = df.ko.stock3[spl,]
test.df = df.ko.stock3[-spl,]
```

#### Now training the tree
```{r}
set.seed(1127, sample.kind = "Rejection")
regtree_cv <- rpart(KOnextday ~ ., data=train.df,cp=0.003,method="anova")
plotcp(regtree_cv)
```

#### Conclusion 1: From above graph, we can conclude/arrive at the optimal cp value of 0.009
#### Now using this cp value to train the tree
```{r}
set.seed(1127, sample.kind = "Rejection")
optimal.tree.cv <- rpart(KOnextday ~ ., data=train.df, method="anova",cp=0.009)
prp(optimal.tree.cv)
```

```{r}
rpart.plot(optimal.tree.cv,digits=-5,extra=101)
help(rpart.plot)
```

#### Lets get predictions for regression models:

```{r}
test.df$pred.regtree = predict(optimal.tree.cv, newdata = test.df)
head(test.df) %>% relocate(pred.regtree)
tail(test.df) %>% relocate(pred.regtree)
```

#### Now, calculating the metrics for regression tree model:

#### To get out of sample R square:

```{r}
mean_train = mean(train.df$KOnextday)

# Then, we compute the sum of squared errors (SSE) using our tree:

SSE = sum((test.df$KOnextday - test.df$pred.regtree)^2)

SSE

print(paste("Regression Tree has a SSE of", round(SSE,4)))

# And the total sum of squared errors (SST) using our simple benchmark model
# (the average mpg in the training set)

SST = sum((test.df$KOnextday - mean_train)^2)

# With that, we finally get

OSR2 = 1 - SSE/SST

OSR2

print(paste("Regression Tree has a OSR2 of", round(OSR2,4)))
```

#### MAE for comparisons


```{r}
MAE = mean(abs(test.df$KOnextday - test.df$pred.regtree))
MAE
print(paste("Regression Tree has a MAE of", round(MAE,4)))
```


### Classification Tree

```{r}
KOdata = read.csv("KO R data.csv", stringsAsFactors = TRUE)
KOdata$Date<-ymd(KOdata$Date)
KOdata$year<-year(KOdata$Date)
KOdata$month<-month(KOdata$Date)
KOdata2<-dummy_cols(KOdata, select_columns=c('month','Type'), remove_selected_columns = TRUE)
KOdata4 = subset(KOdata2, select = -c(Date,year,month_1) )

head(KOdata4)

set.seed(5, sample.kind = "Rejection")

#split the dataset leaving 80% of observations in the training dataset and 20% in the test dataset:
spl = sample(nrow(KOdata4),0.8*nrow(KOdata4))
#head(spl)

train.KOdata4 = KOdata4[spl,]
test.KOdata4 = KOdata4[-spl,]

testtree<-rpart(KOupdown ~ .-KOnextday, data=train.KOdata4, method="class",cp=0.001)

plotcp(testtree)
```

```{r}
tree<-rpart(KOupdown ~ .-KOnextday, data=train.KOdata4, method="class",cp=0.01)
rpart.plot(tree,extra=102)
```


```{r}
predT = predict(tree, newdata = test.KOdata4, type="class")
test.KOdata4$predKOupdown2 = predT
test.KOdata4<-test.KOdata4%>%relocate(predKOupdown2)
```

```{r}
ConfMatrixT<-table(test.KOdata4$KOupdown,test.KOdata4$predKOupdown2)
rownames(ConfMatrixT)<-c("Observed False", "Observed True")
colnames(ConfMatrixT)<-c("Pred False", "Pred True")
ConfMatrixT
```
For cp=0.01

seed 1=
               Pred False Pred True
  Observed False         59        56   =115
  Observed True          57        80   =137        =54.4%
                                  =58.8%

seed 2=
               Pred False Pred True
  Observed False         41        73   =114
  Observed True          46        92   =138        =54.8%
                                  =55.8%
seed 3=
                Pred False Pred True
  Observed False         54        66   =120
  Observed True          56        76   =132        =52.4%
                                  =53.5%
seed 4=
                Pred False Pred True
  Observed False         41        70   =111
  Observed True          58        83   =141        =56.0%
                                  =54.2%
seed 5=
                Pred False Pred True
  Observed False         32        84   =116
  Observed True          49        87   =136        =54.0%
                                  =50.9%  
                                  
 For cp = 0.001  
   
seed 1=
                 Pred False Pred True
  Observed False         68        47   
  Observed True          67        70               =54.4%
                                  =59.8%
seed 2=
                 Pred False Pred True
  Observed False         55        59
  Observed True          60        78               =54.8%
                                  =56.9%
seed 3=
                 Pred False Pred True
  Observed False         65        55
  Observed True          59        73               =52.4%
                                  =57.0%
seed 4=
                 Pred False Pred True
  Observed False         45        66
  Observed True          64        77               =56.0%
                                  =53.8%
seed 5=
                 Pred False Pred True
  Observed False         53        63
  Observed True          64        72               =54.0%
                                  =53.3%
                                  
cp=0.001 seems to perform better than cp=0.01 regardless of cp plot

End Classification Tree

### Regression Random Forest

```{r}
KOdata3 = subset(KOdata2, select = -c(Date,year) )
#split the dataset leaving 80% of observations in the training dataset and 20% in the test dataset:
spl = sample(nrow(KOdata3),0.8*nrow(KOdata3))
#head(spl)

train.KOdata3 = KOdata3[spl,]
test.KOdata3 = KOdata3[-spl,]

```

```{r}
x = train.KOdata3[,-1]
y = train.KOdata3$KOnextday


set.seed(123, sample.kind="Rejection")
tuneRF(x, y, mtryStart = 4, stepFactor = 2, ntreeTry=100, nodesize=50, improve=0.01,doBest=TRUE)


rf = randomForest(KOnextday~.-KOupdown, 
                      data=train.KOdata3, 
                      ntree=100,
                      nodesize=50,
                      mtry=14)


plot(rf)
varImpPlot(rf)

mean = mean(train.KOdata3$KOnextday)
pred_rf = predict(rf, newdata=test.KOdata3)
SSE_rf = sum((test.KOdata3$KOnextday - pred_rf)^2)
SST_rf = sum((test.KOdata3$KOnextday - mean)^2)
OSR2_rf = 1 - SSE_rf/SST_rf
OSR2_rf
```

### Artificial neural network

```{r}
str(KOdata4)

set.seed(1, sample.kind="Rejection")
spl = sample(nrow(KOdata4), 0.8*nrow(KOdata4)) 
intermediate = KOdata4[spl,]
test = KOdata4[-spl,]

set.seed(1, sample.kind="Rejection")
spl2 = sample(nrow(intermediate), 2/3*nrow(intermediate)) 
train = intermediate[spl2,]
valid = intermediate[-spl2,]

```



```{r}
maxVals = apply(train, 2, max)
minVals = apply(train, 2, min)

#maxVals
#minVals
```

```{r}
scaled_train = as.data.frame(scale(train, center = minVals, 
                                scale = maxVals - minVals))

scaled_valid = as.data.frame(scale(valid, center = minVals, 
                                     scale = maxVals - minVals))

scaled_test = as.data.frame(scale(test, center = minVals, 
                                     scale = maxVals - minVals))
```

#### The following code added for NN with Regression (NNR)
```{r}
KOdata5 = subset(KOdata2, select = -c(Date,year,month_1,KOupdown) )


set.seed(1, sample.kind="Rejection")
spl.nnr = sample(nrow(KOdata5), 0.8*nrow(KOdata5)) 
intermediate.nnr = KOdata5[spl.nnr,]
test.nnr = KOdata5[-spl.nnr,]

set.seed(1, sample.kind="Rejection")
spl2.nnr = sample(nrow(intermediate.nnr), 2/3*nrow(intermediate.nnr)) 
train.nnr = intermediate.nnr[spl2.nnr,]
valid.nnr = intermediate.nnr[-spl2.nnr,]
```

```{r}
maxVals.nnr = apply(train.nnr, 2, max)
minVals.nnr = apply(train.nnr, 2, min)

maxVals.nnr
minVals.nnr
```

```{r}
scaled_train.nnr = as.data.frame(scale(train.nnr, center = minVals.nnr, 
                                scale = maxVals.nnr - minVals.nnr))

scaled_valid.nnr = as.data.frame(scale(valid.nnr, center = minVals.nnr, 
                                     scale = maxVals.nnr - minVals.nnr))

scaled_test.nnr = as.data.frame(scale(test.nnr, center = minVals.nnr, 
                                     scale = maxVals.nnr - minVals.nnr))
```


```{r}
set.seed(1, sample.kind="Rejection")
neural1 = neuralnet(KOupdown~Kovolume+Kochange+NYSEchange+Pepsichange+PPIChange+MCDchange+month_5, data = scaled_train, hidden=c(4), linear.output=F,threshold=0.005, stepmax=50000,lifesign='full', lifesign.step=500)
```


```{r}
plot(neural1)
```

```{r}
set.seed(2, sample.kind="Rejection")
neural2 = neuralnet(KOupdown~.-KOnextday, data = scaled_train, hidden=c(6), linear.output=T,threshold=0.01, stepmax=200000,lifesign='full', lifesign.step=500)
```

```{r}
plot(neural2)
```

```{r}
set.seed(1, sample.kind="Rejection")
neural3 = neuralnet(KOnextday~Kovolume+Kochange+NYSEchange+Pepsichange+PPIChange+MCDchange+month_5, data = scaled_train.nnr, hidden=c(4), linear.output=T,threshold=0.005, stepmax=50000,lifesign='full', lifesign.step=500)
```

```{r}
plot(neural3)
```


```{r}
set.seed(1, sample.kind="Rejection")
neural4 = neuralnet(KOnextday~.-KOupdown, data = scaled_train.nnr, hidden=c(7), linear.output=T,threshold=0.005, stepmax=200000,lifesign='full', lifesign.step=500)
```

```{r}
plot(neural4)
```


```{r}
pred.valid.neural4 = predict(neural4, newdata=scaled_valid.nnr)
summary(pred.valid.neural4)
```


```{r}
m = min(train.nnr$KOnextday)
M = max(train.nnr$KOnextday)

valid.pred.nn = (pred.valid.neural4 * (M - m)) + m

summary(valid.pred.nn)
```


```{r}
train.mean = mean(train.nnr$KOnextday)
SSE.valid = sum((valid.pred.nn - valid.nnr$KOnextday)^2)
SST.valid = sum((train.mean - valid.nnr$KOnextday)^2)

1 - SSE.valid/SST.valid

OSR1 = 1 - SSE.valid/SST.valid
```

```{r}
set.seed(1, sample.kind="Rejection")
neural5 = neuralnet(KOnextday~.-KOupdown, data = scaled_train.nnr, hidden=c(7), linear.output=T,threshold=0.5, stepmax=100000,lifesign='full', lifesign.step=500)
```

```{r}
plot(neural5)
```

```{r}
pred.valid.neural5 = predict(neural5, newdata=scaled_valid.nnr)
m = min(train.nnr$KOnextday)
M = max(train.nnr$KOnextday)
valid.pred.nn = (pred.valid.neural5 * (M - m)) + m

train.mean = mean(train.nnr$KOnextday)
SSE.valid = sum((valid.pred.nn - valid.nnr$KOnextday)^2)
SST.valid = sum((train.mean - valid.nnr$KOnextday)^2)

1 - SSE.valid/SST.valid

OSR2 = 1 - SSE.valid/SST.valid
```

#### Tried various neural network models with various combinations of parameters to bring the OSR2 value down.

c(4,2)
neural5 = neuralnet(KOnextday~.-KOupdown, data = scaled_train, hidden=c(4,2), linear.output=T,threshold=0.0025, stepmax=50000,lifesign='full', lifesign.step=500)
OSR2 = 1 - SSE.valid/SST.valid -4.907963

neural5 = neuralnet(KOnextday~.-KOupdown, data = scaled_train, hidden=c(9), linear.output=T,threshold=0.006, stepmax=100000,lifesign='full', lifesign.step=500)

OSR2 = -1.411816

neural5 = neuralnet(KOnextday~.-KOupdown, data = scaled_train, hidden=c(10), linear.output=T,threshold=0.006, stepmax=100000,lifesign='full', lifesign.step=500)
Warning: Algorithm did not converge in 1 of 1 repetition(s) within the stepmax.

neural5 = neuralnet(KOnextday~.-KOupdown, data = scaled_train, hidden=c(8), linear.output=T,threshold=0.006, stepmax=100000,lifesign='full', lifesign.step=500)
Warning: Algorithm did not converge in 1 of 1 repetition(s) within the stepmax.

set.seed(1, sample.kind="Rejection")
neural5 = neuralnet(KOnextday~.-KOupdown, data = scaled_train, hidden=c(7), linear.output=T,threshold=0.005, stepmax=100000,lifesign='full', lifesign.step=500)
OSR2 = -0.8957044

neural5 = neuralnet(KOnextday~.-KOupdown, data = scaled_train, hidden=c(6), linear.output=T,threshold=0.003, stepmax=100000,lifesign='full', lifesign.step=500)
OSR2 = -46.27811

neural5 = neuralnet(KOnextday~.-KOupdown, data = scaled_train, hidden=c(6), linear.output=T,threshold=0.001, stepmax=100000,lifesign='full', lifesign.step=500)
OSR2 = -56.02714

neural5 = neuralnet(KOnextday~.-KOupdown, data = scaled_train, hidden=c(7), linear.output=T,threshold=0.01, stepmax=100000,lifesign='full', lifesign.step=500)
OSR2 = -0.7478942

neural5 = neuralnet(KOnextday~.-KOupdown, data = scaled_train, hidden=c(7), linear.output=T,threshold=0.05, stepmax=100000,lifesign='full', lifesign.step=500)
OSR2 = -0.6676118

hidden=c(9)
OSR2 = -0.6626675

=c(10)
OSR2 = -0.9058829

neural5 = neuralnet(KOnextday~.-KOupdown, data = scaled_train, hidden=c(9), linear.output=T,threshold=0.07, stepmax=100000,lifesign='full', lifesign.step=500)
OSR2 = -0.6233809

neural5 = neuralnet(KOnextday~.-KOupdown, data = scaled_train, hidden=c(7), linear.output=T,threshold=0.07, stepmax=100000,lifesign='full', lifesign.step=500)
OSR2 = -0.6033476

neural5 = neuralnet(KOnextday~.-KOupdown, data = scaled_train, hidden=c(7), linear.output=T,threshold=0.1, stepmax=100000,lifesign='full', lifesign.step=500)
OSR2 = -0.5470808

neural5 = neuralnet(KOnextday~.-KOupdown, data = scaled_train, hidden=c(7), linear.output=T,threshold=0.5, stepmax=100000,lifesign='full', lifesign.step=500)
OSR2 = -0.08085926

0.6
OSR2 = -0.08401804
